we’re asking wrong questions youtube facebook new zealandit’s time real conversation infrastructure incentives big tech provides farright extremistslate saturday night facebook shared dizzying statistics begin illustrate scale online impact new zealand massacre gunman’s video spread across social mediaaccording social network graphic highdefinition video attack uploaded users  million times first hours  million copies video facebook’s automatic detection systems automatically blocked  million left roughly  copies ricocheting around platform viewed liked shared commented facebook’s two billion usersyoutube dealt similar deluge washington post reported monday youtube took “unprecedented steps” stanch flow copies video mirrored reuploaded and cases repackaged edited elude moderation filters hours shooting one youtube executive revealed new uploads attacker’s livestream appeared platform “as quickly one per second”the volume uploads staggering — says power platforms collective desire share horrific acts violence footage murder least innocent people broadcast distributed globally dredges deeply uncomfortable questions biggest social networks including existential one ability connect speed scale benefit detriment greater goodthe platforms directly blame act mass terror shooter’s online presence chilling reminder power influence joan donovan director technology social change research project harvard told wake shooting “if platform companies going provide broadcast tools sharing hateful ideologies going share blame normalizing them”numerical disclosures kind unusual facebook youtube there’s credit due platforms marshaling resources stop video spreading one hand stats could interpreted rare bit transparency behalf companies — small gesture signal understand responsibility protect users rein monster scale built facebook youtube’s choice pull back curtain also careful bit corporate messaging youtube chose share one vague stat facebook never mentioned many views shares comments  videos received taken down it’s less open book attempt show work assuage critics that despite claims negligence tech giants are fact “on it” troubling it’s also bid reframe conversation toward content moderation rather addressing role platforms play fostering emboldening online extremismcontent moderation important logistically thorny existential implementation new monitoring systems constant tweaking algorithmic filters robust investments human intervention comprehensive trust safety policies written experts companies continue get better protecting users offensive content press silicon valley obsess granular issues fast social networks took video focus symptoms instead disease horror new zealand massacre wakeup call big tech occasion interrogate architecture social networks incentivize reward creation extremist communities content focusing moderation means facebook youtube platforms reddit don’t answer ways platforms meticulously engineered encourage creation incendiary content rewarding eyeballs likes and cases ad dollars reward system creates feedback loop slowly pushes unsuspecting users rabbit hole toward extremist ideas communitieson facebook reddit might mean ways people encouraged share propaganda divisive misinformation violent images order amass likes shares might mean creation private communities toxic ideologies allowed foment unchecked youtube incentives created cottage industries shock jocks livestreaming communities dedicated bigotry cloaked amateur philosophy youtube personalities communities spring around videos become important recruiting tools farright fringes cases new features like “super chat” allows viewers donate youtube personalities livestreams become major fundraising tools platform’s worst users — essentially acting online telethons white nationalists part what’s unsettling new zealand shooting suspect’s online persona lays bare forces occasionally come together violent ends supposed digital footprint isn’t upsetting content much appears designed delight fellow extremists decision call attack “real life effort post” reflects eerie merging conspiratorial hate pages online forums real world — grim reminder online communities may emboldening nudging violent unstable individualsstewards broken online ecosystem need accept responsibility — moderating content cultures behaviors foster accepting responsibility require series hard conversations behalf tech industry’s powerful companies it’ll involve big questions morality business models turned startups moneyprinting behemoths even tougher questions whether connectivity scale universal good untenable phenomenon that’s slowly pushing us toward disturbing outcomesand it’s hardly conversations facebook youtube want have they’re ones desperately need nowthe times committed publishing diversity letters editor we’d like hear think articles tips here’s emaillettersnytimescomfollow new york times opinion section facebook twitter nytopinion instagramcharlie warzel new york times opinion writer large covers technology media politics online extremism cwarzel