block shooter’s viral aspirationshow curb exposure videos like shootings new zealandin “we’re asking wrong questions youtube facebook new zealand” charlie warzel wrote online impact video streamed allegedly gunman shootings christchurch need social media tech companies take responsibility content posted extremists platformsreaders responded questions concerns policing online content mr warzel responded readers comments replies follow edited length clarity — rachel l harris lisa tarchak senior editorial assistantsbob concord mass would bad deleting accounts upload videos clearly violate terms use agreement users knew consequences sharing certain material there’d significantly less sharing videos course eliminating users would reduce number users platform could perceived negatively affecting shareholder valuecharlie warzel worried tech companies getting business deplatforming you’re describing is essentially standardpractice terms service enforcement it’s frequently lost big tech’s freespeech debates every user platforms entered agreement abide company’s rules conduct granted companies broad sweeping permission suspend permanently remove offending users contentthat’s say platforms well within right impose harsh bans upload attempt disseminate terroristic propaganda and many respects companies already this last year twitter announced suspended  million terrorist accounts since the christchurch video potentially complicated big tech platforms unprecedented nature footage — livestreamed high definition horrifically graphic — inherent newsworthiness meant cross section trolls curious onlookers even media organizations felt inclined repost footage immediate aftermath it’s important well remember it’s “people algorithms” sharing stuff tech platforms tend bristle policing speech kind would likely take issue blanket suspension journalists may recklessly shared reposted videobut perhaps fallout christchurch pressure tech companies draw clear line sand around videos undoubtedly fall buckets terroristic content graphic mass violence strict rules around redistributing images mass murder say might compel loudest megaphones think twice sharing there’s decent argument made what’s needed current media ecosystem little friction restraint platforms course main contributors frictionless sharing environment it’s potentially intractable problem and editorial board argued last week “it’s telling platforms must make less functional interests public safety”antony shugaar la jolla calif kind footage every bit illegal child pornography — possession posting viewing all it’s harm done making kinds videos that’s issue well corrosive effects presence society say nothing effects victimswarzel it’s particularly revealing watching situation play overseas last monday new zealand’s office film literature classification declared illegal view possess distribute video similarly australian telecom companies took aggressive action sites still hosting footage attack blocking browser access sites like chan chan message board voat video platform liveleakobviously free speech concerns united states complicate discussion around internet service providers blocking access major websites highly doubt we’ll see anything america approximating swift unilateral action said you’re hinting fascinating argument that’s likely gain steam around instituting legal penalties distributing acts terroristic violence propagandahowever issues constitutes possession digital world contentious i’m thinking edge cases like accidental downloads dissemination filesharing services instance murky legal territory that’s depth think you’d need strict legal definitions like child pornography laws constitutes terroristic violent act that’s protected first amendment distinguish newsworthy footage act intent video taken account matter uploaded made it anyone really ready willing tackle questionsrather government setting limits speech seems far likely we’ll see stricter guidelines moderation platforms themselves private companies example web hosting companies last year’s mass shooting synagogue pittsburgh web hosting provider joyent suspended service social network gab response antisemitic conspiratorial posts left shooting suspect tom new york facebook youtube rightfully examined critically today general public legislators wondering though actions could taken toward platforms like chan chan also significant damage often breeding ground host platform hate speech radicalization forums operate differently sites like facebook youtube obviously best practices regulations evolved could evolve curb impact atrisk users willful actorswarzel chans chans world distinct tricky challenge lack big tech business model owners largely free scrutiny publicfacing platforms receive possess nowhere near dizzying scale facebook google yet they’re important influential engines hate online forums like these top solidifying communities around toxic ideologies also breeding grounds many memes viral content distributed larger social networks like reddit twitter facebook last year example group called network contagion research institute found chan’s “politically incorrect” message board “served prolific source many offensive memes eventually spread widely across internet”since communities run privately owners tend see sites raucous experiments maximalist free speech it’s unclear anything could really change there’s always possibility internet service providers blocking access web hosting clients terminating site’s contracts exert pressure that’s hypothetical best said conspiratorial hate jumps forum pages real world it’s possible communities get greater scrutiny law enforcement last week public schools charlottesville va shut two days threats “ethnic cleansing” massacre posted chan chan posts spurred vigorous investigation local police well fbi friday yearold suspect arrested connection posts it’s one isolated incident emergence actual investigations credible online threats well real world consequences could noticeable effect worst variety trollsand then internet’s seediest message board communities choose police platforms all viable solution series dedicated empowered moderators communities sites like reddit modicum success this even dedicated teams “mods” tend lack support resources need site’s administrators forums like chan chan sometimes moderators but buzzfeed news recently reported “quixotic quest clean internet’s deepest pit misery meme there”mark gardiner kansas city mo acrosstheboard builtin lag even minutes social media sites would enabled facebook youtube etc eliminate viral propagation vile video lag five minutes time user posts content goes live similar lag reposting would hurt meaningful social communication would reduce brainless “virality” would also greatly improve ability social media companies prevent obviously antisocial uses platforms would new zealand psychopath gone rampage knew would livestreamed maybe not even did would able inspire millions white nationalistswarzel i’ve seen “tape delay” idea debated last days it’s interesting one practice though seems quite difficult carry out example add upload lag videos certain accounts it’s videos mean videos ought flagged artificial intelligence potential violence wednesday evening facebook argued flagging systems adequate screening catching nudity certain violent imagery would likely deliver false positives innocuous videos wellso human moderators sophistication internet’s worst communities seems necessitate human moderation parse innocent pranks insidious trolling welltrained moderators adequate time pore videos could suss satire hate speech parse cultural standards norms might cause video innocuous one region deeply offensive another but great reporting revealed recently moderators tend outside contractors subjected daily torrents psychologically traumatizing content often without support pay deserve rather spend time video they’re forced pass judgment matter seconds still they’re far expensive algorithm far less efficient tech companies tend prefer deeply imperfect ai solutions hovering issues platforms’ gargantuan scale hours content uploaded youtube every minute facebook disclosed videos time reached eight billion views day platforms used tout metrics triumphs connectivity seems they’ve also become incredible liabilities former colleague mine — website comment moderator — wrote recently “sites like facebook youtube twitter failed support clear repeatable moderation guidelines years platforms absorbed basic social functions”the times committed publishing diversity letters editor we’d like hear think articles tips here’s emaillettersnytimescomfollow new york times opinion section facebook twitter nytopinion instagramcharlie warzel new york times opinion writer large covers technology media politics online extremism cwarzel