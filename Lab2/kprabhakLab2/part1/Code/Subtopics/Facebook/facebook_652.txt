big tech designed toxicwhen comes explaining facebook youtube twitter become hotbeds extremism propaganda bigotry there’s tendency overcomplicate things that’s understandable algorithms govern platforms unknowable trade secrets are cases billions users account for meaty issues free speech copyright law playing real time across borders technology confusing and yes it’s true tech companies dealing thorny problems likely universally satisfying outcome big tech’s problems indeed dizzying manifold last years taught us there’s occam’s razor quality explanation toxicity online platforms original sin seems isn’t complicated it’s prioritization growth — else expense us use servicesthe recent example came tuesday morning bloomberg news published story chronicling youtube’s struggles quash misinformation conspiracies incendiary content according report current former youtube employees said company ignored warnings change youtube’s recommendation engine were cases discouraged seeking videos might violate youtube’s rules preserve sense plausible deniability employee fears “were sacrificed engagement” ambitious goals set hit one billion hours viewing day algorithms tweaked accordingly “we weeds trying hit goals drive usage site” one former senior manager confessed piece “i don’t know really picked heads”as technology advances continue blur lines public private sign charlie warzel’s limitedrun newsletter explore whats stake itthe story shouldn’t shocking reports inside youtube echo insider tales large tech platforms — familiar pattern ruthless optimization users attention gone wrongthe youtube employee’s quote reminded conversation i’d years back former member twitter’s product team “leading ipo revenue growth ceo down” employee told me suggesting that frantic race look good wall street company deprioritized fixing systemic issues including rampant harassment problem others inside twitter back agreed “i see lot decisions made terms growth came handle abuse get” leslie miley former engineering manager twitter told timegrowth cost it’s mantra familiar inside facebook well internal memo surfaced last year buzzfeed news revealed “we connect people period that’s work growth justified” facebook senior executive andrew bosworth wrote memo june  separate section advancing argument human connections via facebook “de facto good” appears grapple downsides connection “maybe costs someone life exposing someone bullies … maybe someone dies terrorist attack coordinated tools” wrotemr bosworth suggested memo thought experiment “i don’t agree post today didn’t agree wrote it” said facebook’s rapid rise two billionplus users numerous privacy debacles steady stream reported negative revelations suggest that like counterparts company’s quest expansion trumped pressing concerns privacy transparency new york times investigation last year reported that “bent growth” facebook executives “ignored warning signs” facebook could “disrupt elections broadcast viral propaganda inspire deadly campaigns hate around globe”scale also seductive engineering level bottom line aside adding users engagement one interpretation might signal you’re giving people want  asked former senior facebook employee staff members felt sense blame facebook’s inability stop spread misinformation plagued platform election exactly employee explained “they believe extent something flourishes goes viral facebook — it’s reflection company’s role reflection people want deeply rational engineer’s view tends absolve responsibility probably”we see sensibility today way platforms tend obfuscate deflect responsibility last week youtube executive argued recommendation algorithms weren’t designed nudge users toward extreme videos similarly twitter continue argue designed specifically disproportionately hostile women people color facebook argue certainly designed help foreign countries interfere electionsbut defensive posture seems concerned intent even take platforms word intend profit extremism become hubs radicalization online doesn’t mean doesn’t happen intent far less important actual outcomes outcomes appear suggest platforms intentionally designed keep glued screen one video one retweet one outraged share hate read mess unwound fixed complicated questions answer got first place much less complicated big tech wants think intentionally not designed way times committed publishing diversity letters editor we’d like hear think articles tips here’s emaillettersnytimescomfollow new york times opinion section facebook twitter nytopinion instagramcharlie warzel new york times opinion writer large covers technology media politics online extremism welcomes tips feedback charliewarzelnytimescom  cwarzel